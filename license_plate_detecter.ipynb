{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69041794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "#pip install opencv-python pandas easyocr\n",
    "\n",
    "import imutils\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Input, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8bff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path\n",
    "folder_path = 'C:/Users/Dell/JupyterPythoncodes/DataScienceSoulpageit assignment/license_plates_detection_train'\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "# Loop through each image file\n",
    "for image_file in image_files:\n",
    "    # Read the image\n",
    "    image_path = os.path.join(folder_path, image_file)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image from BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    image = imutils.resize(image, width=500)\n",
    "    img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the original image\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(10,7))\n",
    "    ax[0,0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    ax[0,0].set_title('Original Image')\n",
    "\n",
    "    # RGB to Gray scale conversion\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ax[0,1].imshow(gray, cmap='gray')\n",
    "    ax[0,1].set_title('Grayscale Conversion')\n",
    "\n",
    "    # Noise removal with iterative bilateral filter(removes noise while preserving edges)\n",
    "    gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "    ax[1,0].imshow(gray, cmap='gray')\n",
    "    ax[1,0].set_title('Bilateral Filter')\n",
    "\n",
    "    # Find Edges of the grayscale image\n",
    "    edged = cv2.Canny(gray, 170, 200)\n",
    "    ax[1,1].imshow(edged, cmap='gray')\n",
    "    ax[1,1].set_title('Canny Edges')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find contours based on Edges\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:30] #sort contours based on their area keeping minimum required area as '30' (anything smaller than this will not be considered)\n",
    "    NumberPlateCnt = None #we currently have no Number plate contour\n",
    "\n",
    "    # loop over our contours to find the best possible approximate contour of number plate\n",
    "    count = 0\n",
    "    for c in cnts:\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "            if len(approx) == 4:  # Select the contour with 4 corners\n",
    "                NumberPlateCnt = approx #This is our approx Number Plate Contour\n",
    "                x,y,w,h = cv2.boundingRect(c)\n",
    "                ROI = img[y:y+h, x:x+w]\n",
    "                break\n",
    "\n",
    "    if NumberPlateCnt is not None:\n",
    "        # Drawing the selected contour on the original image\n",
    "        cv2.drawContours(image, [NumberPlateCnt], -1, (0,255,0), 3)\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Detected license plate\")\n",
    "        plt.show()\n",
    "\n",
    "        # Find bounding box and extract ROI\n",
    "        plt.imshow(ROI)\n",
    "        plt.title(\"Extracted license plate\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(NumberPlateCnt) #if the extracted license plate is tilted/rotated\n",
    "\n",
    "        # Distance between (x1, y1) and (x2, y2)\n",
    "        def dist(x1, x2, y1, y2):\n",
    "            return ((x1-x2)**2+(y1-y2)**2)**0.5\n",
    "\n",
    "        idx=0\n",
    "        m=0\n",
    "        # To find the index of coordinate with maximum y-coordinate\n",
    "        for i in range(4):\n",
    "            if NumberPlateCnt[i][0][1]>m:\n",
    "                idx=i\n",
    "                m=NumberPlateCnt[i][0][1]\n",
    "\n",
    "        # Assign index to the previous coordinate\n",
    "        if idx==0:\n",
    "            pin=3\n",
    "        else:\n",
    "            pin=idx-1\n",
    "\n",
    "        # Assign index to the next coordinate\n",
    "        if idx==3:\n",
    "            nin=0\n",
    "        else:\n",
    "            nin=idx+1\n",
    "\n",
    "        # Find distances between the acquired coordinate and its previous and next coordinate\n",
    "        p=dist(NumberPlateCnt[idx][0][0], NumberPlateCnt[pin][0][0], NumberPlateCnt[idx][0][1], NumberPlateCnt[pin][0][1])\n",
    "        n=dist(NumberPlateCnt[idx][0][0], NumberPlateCnt[nin][0][0], NumberPlateCnt[idx][0][1], NumberPlateCnt[nin][0][1])\n",
    "\n",
    "        # The coordinate that has more distance from the acquired coordinate is the required second bottom-most coordinate\n",
    "        if p>n:\n",
    "            if NumberPlateCnt[pin][0][0]<NumberPlateCnt[idx][0][0]:\n",
    "                left=pin\n",
    "                right=idx\n",
    "            else:\n",
    "                left=idx\n",
    "                right=pin\n",
    "            d=p\n",
    "        else:\n",
    "            if NumberPlateCnt[nin][0][0]<NumberPlateCnt[idx][0][0]:\n",
    "                left=nin\n",
    "                right=idx\n",
    "            else:\n",
    "                left=idx\n",
    "                right=nin\n",
    "            d=n\n",
    "        print(left, right)\n",
    "        left_x=NumberPlateCnt[left][0][0]\n",
    "        left_y=NumberPlateCnt[left][0][1]\n",
    "        right_x=NumberPlateCnt[right][0][0]\n",
    "        right_y=NumberPlateCnt[right][0][1]\n",
    "        print(left_x, left_y, right_x, right_y)\n",
    "\n",
    "        # Finding the angle of rotation by calculating sin of theta\n",
    "        opp=right_y-left_y\n",
    "        hyp=((left_x-right_x)**2+(left_y-right_y)**2)**0.5\n",
    "        sin=opp/hyp\n",
    "        theta=math.asin(sin)*57.2958\n",
    "\n",
    "        # Rotate the image according to the angle of rotation obtained\n",
    "        image_center = tuple(np.array(ROI.shape[1::-1]) / 2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(image_center, theta, 1.0)\n",
    "        result = cv2.warpAffine(ROI, rot_mat, ROI.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "        # The image can be cropped after rotation( since rotated image takes much more height)\n",
    "        if opp>0:\n",
    "            h=result.shape[0]-opp//2\n",
    "        else:\n",
    "            h=result.shape[0]+opp//2\n",
    "\n",
    "        result=result[0:h, :]\n",
    "        plt.imshow(result)\n",
    "        plt.title(\"Plate obtained after rotation\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3c8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "import pandas as pd\n",
    "import cv2\n",
    "#import cv2_imshow\n",
    "import os\n",
    "\n",
    "# read annotation file\n",
    "df = pd.read_csv(\"C:/Users/Dell/JupyterPythoncodes/DataScienceSoulpageit assignment/Licplatesdetection_train.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9877fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Set up matplotlib to display images inline in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Process each row in the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    img_id = row['img_id']\n",
    "    x_min, y_min, x_max, y_max = int(row[\"xmin\"]), int(row[\"ymin\"]), int(row[\"xmax\"]), int(row[\"ymax\"])\n",
    "    \n",
    "    # Print the bounding box coordinates\n",
    "    print(f\"Image ID: {img_id}, Coordinates: ({x_min}, {y_min}, {x_max}, {y_max})\")\n",
    "    \n",
    "    # Read image\n",
    "    img_path = os.path.join(\"C:\\Users\\Dell\\JupyterPythoncodes\\DataScienceSoulpageit assignment\\license_plates_detection_train\", img_id)  # Adjust directory as necessary\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is not None:\n",
    "        # Print image shape\n",
    "        print(f\"Image Shape: {img.shape}\")  # Output the dimensions of the image\n",
    "        \n",
    "        # Crop the region containing the license plate\n",
    "        plate = img[y_min:y_max, x_min:x_max]\n",
    "        \n",
    "        # Convert BGR image to RGB\n",
    "        plate_rgb = cv2.cvtColor(plate, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display the cropped license plate\n",
    "        plt.figure(figsize=(5,5))  # Set the figure size (optional)\n",
    "        plt.imshow(plate_rgb)\n",
    "        plt.axis('off')  # Turn off axis numbers and ticks\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Failed to read image {img_id}\")\n",
    "# Process each row in the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    img_id = row['img_id']\n",
    "    x_min, y_min, x_max, y_max = int(row[\"xmin\"]), int(row[\"ymin\"]), int(row[\"xmax\"]), int(row[\"ymax\"])\n",
    "\n",
    "    # Print the bounding box coordinates\n",
    "    print(f\"Image ID: {img_id}, Coordinates: ({x_min}, {y_min}, {x_max}, {y_max})\")\n",
    "\n",
    "    # Read image\n",
    "    img_path = os.path.join(\"C:\\Users\\Dell\\JupyterPythoncodes\\DataScienceSoulpageit assignment\\license_plates_detection_train\", img_id)  # Adjust directory as necessary\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    if img is not None:\n",
    "        # Print image shape\n",
    "        print(f\"Image Shape: {img.shape}\")  # Output the dimensions of the image\n",
    "\n",
    "        # Crop the region containing the license plate\n",
    "        plate = img[y_min:y_max, x_min:x_max]\n",
    "\n",
    "        # Show the cropped license plate\n",
    "        cv2_imshow(plate)\n",
    "    else:\n",
    "        print(f\"Failed to read image {img_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71499ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bbox = df.loc[df['img_id']=='11.jpg']\n",
    "x_min, y_min, x_max, y_max = int(img_bbox[\"xmin\"]), int(img_bbox[\"ymin\"]), int(img_bbox[\"xmax\"]), int(img_bbox[\"ymax\"])\n",
    "print(x_min, y_min, x_max, y_max)\n",
    "# plot the bbox and visualize\n",
    "img = cv2.imread(\"C:/Users/Dell/JupyterPythoncodes/DataScienceSoulpageit assignment/license_plates_detection_train/11.jpg\")\n",
    "print(img.shape) # -> (h, w , 3) ->(BGR)\n",
    "\n",
    "# crop the region\n",
    "plate = img[y_min:y_max,  x_min:x_max]\n",
    "cv2_imshow(plate)\n",
    "# img[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0183bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_characters(image) :\n",
    "    # Preprocess cropped license plate image\n",
    "    img_lp = cv2.resize(image, (333, 75))\n",
    "    img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n",
    "    img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n",
    "\n",
    "    LP_WIDTH = img_binary_lp.shape[0]\n",
    "    LP_HEIGHT = img_binary_lp.shape[1]\n",
    "\n",
    "    # Make borders white\n",
    "    img_binary_lp[0:3,:] = 255\n",
    "    img_binary_lp[:,0:3] = 255\n",
    "    img_binary_lp[72:75,:] = 255\n",
    "    img_binary_lp[:,330:333] = 255\n",
    "\n",
    "    # Estimations of character contours sizes of cropped license plates\n",
    "    dimensions = [LP_WIDTH/6,\n",
    "                       LP_WIDTH/2,\n",
    "                       LP_HEIGHT/10,\n",
    "                       2*LP_HEIGHT/3]\n",
    "    plt.imshow(img_binary_lp, cmap='gray')\n",
    "    plt.title('Contour')\n",
    "    plt.show()\n",
    "    cv2.imwrite('contour.jpg',img_binary_lp)\n",
    "\n",
    "    # Get contours within cropped license plate\n",
    "    char_list = find_contours(dimensions, img_binary_lp)\n",
    "\n",
    "    return char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match contours to license plate or character template\n",
    "def find_contours(dimensions, img) :\n",
    "\n",
    "    # Find all contours in the image\n",
    "    cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Retrieve potential dimensions\n",
    "    lower_width = dimensions[0]\n",
    "    upper_width = dimensions[1]\n",
    "    lower_height = dimensions[2]\n",
    "    upper_height = dimensions[3]\n",
    "\n",
    "    # Check largest 5 or  15 contours for license plate or character respectively\n",
    "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n",
    "\n",
    "    ii = cv2.imread('contour.jpg')\n",
    "\n",
    "    x_cntr_list = []\n",
    "    target_contours = []\n",
    "    img_res = []\n",
    "    for cntr in cntrs :\n",
    "        # detects contour in binary image and returns the coordinates of rectangle enclosing it\n",
    "        intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)\n",
    "\n",
    "        # checking the dimensions of the contour to filter out the characters by contour's size\n",
    "        if intWidth > lower_width and intWidth < upper_width and intHeight > lower_height and intHeight < upper_height :\n",
    "            x_cntr_list.append(intX) #stores the x coordinate of the character's contour, to used later for indexing the contours\n",
    "\n",
    "            char_copy = np.zeros((44,24))\n",
    "            # extracting each character using the enclosing rectangle's coordinates.\n",
    "            char = img[intY:intY+intHeight, intX:intX+intWidth]\n",
    "            char = cv2.resize(char, (20, 40))\n",
    "\n",
    "            cv2.rectangle(ii, (intX,intY), (intWidth+intX, intY+intHeight), (50,21,200), 2)\n",
    "            plt.imshow(ii, cmap='gray')\n",
    "            plt.title('Predict Segments')\n",
    "\n",
    "            # Make result formatted for classification: invert colors\n",
    "            char = cv2.subtract(255, char)\n",
    "\n",
    "            # Resize the image to 24x44 with black border\n",
    "            char_copy[2:42, 2:22] = char\n",
    "            char_copy[0:2, :] = 0\n",
    "            char_copy[:, 0:2] = 0\n",
    "            char_copy[42:44, :] = 0\n",
    "            char_copy[:, 22:24] = 0\n",
    "\n",
    "            img_res.append(char_copy) # List that stores the character's binary image (unsorted)\n",
    "\n",
    "    # Return characters on ascending order with respect to the x-coordinate (most-left character first)\n",
    "\n",
    "    plt.show()\n",
    "    # arbitrary function that stores sorted list of character indeces\n",
    "    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n",
    "    img_res_copy = []\n",
    "    for idx in indices:\n",
    "        img_res_copy.append(img_res[idx])# stores character images according to their index\n",
    "    img_res = np.array(img_res_copy)\n",
    "\n",
    "    return img_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_characters(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
